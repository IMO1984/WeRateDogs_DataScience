{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtweepy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimeit\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import tweepy\n",
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "with open('image_predictions.tsv', 'wb') as file:\n",
    "    pred_data = requests.get(pred_url)\n",
    "    file.write(pred_data.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = open(\"twitter_keys.txt\")\n",
    "lines = keys.readlines()\n",
    "consumer_key = lines[0].split(' ')[1].strip()\n",
    "consumer_secret = lines[1].split(' ')[1].strip()\n",
    "access_token = lines[2].split(' ')[1].strip()\n",
    "access_token_secret = lines[3].split(' ')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred = pd.read_csv('image_predictions.tsv',sep='\\t')\n",
    "tweet_ids = df_imagePred.tweet_id.values\n",
    "len(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timeit.default_timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\",e)\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timeit.default_timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to display the full string from a pandas DataFrame\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df_wrdArchive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_imagePred = pd.read_csv('image_predictions.tsv',sep='\\t')\n",
    "df_tweetStatus = pd.read_json('tweet_json.txt', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive[df_wrdArchive.retweeted_status_id.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive[df_wrdArchive.in_reply_to_status_id.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop those tweets which are either re-tweet or in reply to\n",
    "df_wrdArchive.drop(df_wrdArchive[df_wrdArchive.retweeted_status_id.notna()].index, inplace = True)\n",
    "df_wrdArchive.drop(df_wrdArchive[df_wrdArchive.in_reply_to_status_id.notna()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive[df_wrdArchive.tweet_id.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus[df_tweetStatus.id.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred[df_imagePred.tweet_id.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus[df_tweetStatus['retweeted'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus['retweeted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus.retweeted_status.notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetStatus[df_tweetStatus.retweeted_status.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred[df_imagePred.jpg_url.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imagePred[df_imagePred['jpg_url'] == 'https://pbs.twimg.com/media/CWza7kpWcAAdYLc.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive[df_wrdArchive.tweet_id.isin(df_imagePred[df_imagePred['jpg_url'] == 'https://pbs.twimg.com/media/CWza7kpWcAAdYLc.jpg'].tweet_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.doggo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.floofer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.pupper.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.puppo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong_dog_stage = df_wrdArchive.iloc[:0,:].copy()\n",
    "for index, row in df_wrdArchive.iterrows():\n",
    "    if ((row['doggo'] != \"None\" and (row['floofer'] != \"None\" or row['pupper'] != \"None\" or row['puppo'] != \"None\")) or\n",
    "        (row['floofer'] != \"None\" and (row['doggo'] != \"None\" or row['pupper'] != \"None\" or row['puppo'] != \"None\")) or\n",
    "        (row['pupper'] != \"None\" and (row['doggo'] != \"None\" or row['floofer'] != \"None\" or row['puppo'] != \"None\")) or\n",
    "        (row['puppo'] != \"None\" and (row['doggo'] != \"None\" or row['floofer'] != \"None\" or row['pupper'] != \"None\"))):\n",
    "        df_wrong_dog_stage = df_wrong_dog_stage.append(row,ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong_dog_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "#### WeRateDogs Twitter Archive\n",
    "1. Datetime fields are stored as object instead of datetime.    \n",
    "2. The dog names format should be consistent. Capitalize.\n",
    "3. Replace 'None' with np.nan to indicate the missing values.\n",
    "4. Dogs classified as more than one type(doggo, floofer, pupper and puppo) in some cases. \n",
    "5. Denominator with value other than 10.\n",
    "6. Numerator with value of 0.\n",
    "#### Image Predictions\n",
    "7. Non descriptive column name.(Image Predictions)\n",
    "8. The prediction dog breed names formatting incosistent.\n",
    "9. Many Predicted names in dog breed prediction are not likely to be a dog.\n",
    "#### Tweet Status\n",
    "9. Remove all columns not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1. The columns doggo, floofer, pupper and puppo need to be merged together to form a single column. These are values converted into columns.\n",
    "\n",
    "2. Rename the column **id** to **tweet_id** in tweetStatus and **timestamp** to **created_at** in tweetArchive\n",
    "\n",
    "3. Drop columns that are not needed for our analysis.\n",
    "\n",
    "4. Twiiter archive and status data can be consolidated and merged together to have a well formed observation set as they together form the observation. For that matter, we can add dog breed prediction too, without much overhead as we will keep only the original tweets.\n",
    "\n",
    "5. Dogs rating numerator and denominator are stored seprately, which is not ideal. Rating should be one single column and for that matter Ratings can come in decimal. Lets derive rating in decimal and store it a comlumn call Dogs rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "df_ta_clean = df_wrdArchive.copy()\n",
    "df_img_clean = df_imagePred.copy()\n",
    "df_ts_clean = df_tweetStatus.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1: These are values converted into columns - doggo, floofer, pupper and puppo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "doggo, floffer, pupper and puppo seems to be dog stages as per dogtionary. However, doggo might be an exception as it is sometimes called as affectionately which directly not relate to any age stage. Any dog for that matter can be qualified as doggo. For the sake of keeping it simple lets merge these 4 column into one. During programatic assessment it was found that some dogs had more than one stage. With this cleanup we will loose this additional information. Precedence of the selection in the order doggo, floffer, pupper and puppo - doggo given highest precedence and puppo the lowest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDogStage (row):\n",
    "    if row['doggo'] != \"None\" :\n",
    "        return row['doggo']\n",
    "    if row['floofer'] != \"None\" :\n",
    "        return row['floofer']\n",
    "    if row['pupper'] != \"None\" :\n",
    "        return row['pupper']\n",
    "    if row['puppo'] != \"None\" :\n",
    "        return row['puppo']\n",
    "    \n",
    "df_ta_clean['stage'] = df_ta_clean.apply (lambda row: getDogStage(row), axis=1)\n",
    "df_ta_clean = df_ta_clean.drop(['doggo','floofer','pupper','puppo'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2: Rename the column id to tweet_id in tweetStatus and timestamp to created_at in tweetArchive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "**id** column in tweet status is the tweet_id, though the name suggest something else. Visual assessment confirmed that. Let's rename this column to **tweet_id** facilitate restructing of our gathered data which will help us to simply our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean.rename(columns = {'id':'tweet_id'}, inplace = True)\n",
    "df_ta_clean.rename(columns = {'timestamp':'created_at'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Drop columns that are not needed for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Lets clean up additional column that does not relate to dogs rating explicilty. As one observation should form one entry in the table - and we are interested only in dogs rating lets shed the extra noises in these data sources.\n",
    "\n",
    "**Needed columns:**\n",
    ">**Twitter Archive:**'tweet_id','created_at','name','stage','rating_numerator','rating_denominator','text'\n",
    "\n",
    ">**Twitter Status:** 'tweet_id','created_at','favorite_count','retweet_count'\n",
    "\n",
    ">**Dog breed prediction by Image:** Lets keep all except for img_num. In my opinion we dont need to have p2 and p3 columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean = df_ta_clean[['tweet_id','created_at','name','stage','rating_numerator','rating_denominator','text']].copy()\n",
    "df_ts_clean = df_ts_clean[['tweet_id','created_at','favorite_count','retweet_count']].copy()\n",
    "df_img_clean = df_img_clean[['tweet_id','jpg_url','p1','p1_conf','p1_dog']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: Consolidate Archive, Status, Dog breed predictions into a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Twiiter archive and status data can be consolidated and merged together to have a well formed observation set as they together form the observation. For that matter, we can add dog breed prediction too, without much overhead as we will keep only the original tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "We will do this in step of storing data in master Archive as mentioned in below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Will test in step storing data in master Archiveas mentioned in below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue #5: Dog's rating are stored in two different columns as rating Denominatro and Numerator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Dogs Rating should be in a single column. Eventhough it the Dog's rating that set WeRateDogs standout in the crowd, for data analysis it is not ideal. Hence, derive Rating using numertor/denominator and store in a single column. To keep it simple let's round the value to one decimal point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "There are some errornoius entry in denominator and numerator. These values needs to be cleaned up first. We will work on this tidiness issue at the end of resolving data quality issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "Will do later when tidiness issue coding is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1: Datetime fields are stored as object instead of datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Change column dataType of timestamp (in archive) and created_at(in tweet status) to datetime datatype with same format. Please keep a note that in previous step(Tidiness Issue #2) column name 'timestamp' in archive been changed to 'created_at'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean['created_at'] = pd.to_datetime(df_ta_clean['created_at'], utc=False)\n",
    "df_ts_clean['created_at'] = pd.to_datetime(df_ts_clean['created_at'], utc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2: Dog names in archive is not consistent. Make the name capitalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Dog names in archive is not consistent. Make the name capitalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean['name'] = df_ta_clean.name.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrdArchive['name'].str.islower().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean['name'].str.islower().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean[df_ta_clean['name'] != None].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Replace 'None' with np.nan to indicate the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "There are entries in dataset where \"None\" is cell value wehere as in some other places it is NaN. Lets make this consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean = df_ta_clean.replace('None', np.nan)\n",
    "df_ts_clean = df_ts_clean.replace('None', np.nan)\n",
    "df_img_clean = df_img_clean.replace('None', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean[df_ta_clean.stage.notna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean[df_ta_clean.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean[df_ts_clean.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean[df_img_clean.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: Dogs classified as more than one type(doggo, floofer, pupper and puppo) in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "As the issue describe, there are Many dogs which has been categorized as more than one stage (doggo, floofer, pupper and puppo). This needs to be fixed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code\n",
    "This already has been taken care in the Issue #1 in Tidiness cleaning. Please refer to Define section of that issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "doggo, floofer, pupper and puppo has already been converted into a single column. Therefore, it can not hold more than one value in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.stage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5: Denominator with value other than 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Most of the reating denominator (>95%) are having the value 10 which is standard. Though, it was mentioned in the begining that the rating system in WeRateDogs is what set them apart, but in this case we can standardize the denominator to 10. This will not have any impact on the overall ratings given to a dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.loc[df_ta_clean['rating_denominator'] != 10,'rating_denominator' ] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean[df_ta_clean['rating_denominator'] != 10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6: Numertor with value 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Rating with 0 does not seems to be a realistic one. We also dont have any standard value to set in this case either. Lets drop those entries where we have numerator 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.drop(df_ta_clean[df_ta_clean['rating_numerator'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean[df_ta_clean['rating_numerator'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7: Image Predictions Non descriptive column name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Column names in dog breed predictions by image are not descriptive enough. Lets give them more meaningful names to easily relate to the content of the columns and use them effectively. Not only that, from analysis perspective it is enough to keep the first set of prediction outcome and drop the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.rename(columns = {'p1':'first_pridicted_breed',\n",
    "                              'p1_conf': 'first_pridiction_confidence',\n",
    "                              'p1_dog':'is_first_pridiction_dog_breed',\n",
    "                             }, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #8: The predicted dog breed names formatting incosistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Predicted dog breed naming convention are not consistent. Lets make it consistent by capitalizing first letter of every word. Please note, in some cases there are multiple words in a single dog breed separated by either a underscore or space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean['first_pridicted_breed'] = df_img_clean.first_pridicted_breed.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.first_pridicted_breed.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #9: Many predicted dog breed names are not dog breed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "It is true that some predicted dog breed are not dog breeds and the same is flagged as false in such cases. We can either drop these entries or keep it as it will not harm as much. The upside is we can still have the picture url available in master and dog breed can be corrected manually. Manual assessment revealed that in some cases the background picture of dog took precedence, in other cases there are no dog picture at all. For the sake of keeping this wrangling part clean, lets remove such entries from the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out how many prediction ended up with no dog breed\n",
    "df_img_clean[df_img_clean['is_first_pridiction_dog_breed'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.drop(df_img_clean[df_img_clean['is_first_pridiction_dog_breed'] == False].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean[df_img_clean['is_first_pridiction_dog_breed'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #10: Delete not needed column from all three datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "One final cleanup is still necessary to see if there are any duplicate columns exist. If yes, drop them. Revisit the columns to see if any column that is not needed for our nanalysis still exist. If yes then drop them as well. This will ensure good quality and concise data and we can merge them easily to have good master archive data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.Series(list(df_ta_clean.columns) + list(df_ts_clean.columns) + list(df_img_clean.columns))\n",
    "columns[columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We need **tweet_id** to merge all three datasets. Will kep it. Lets analyse **created_at**. This occurs in both archive and status dataset. Lets have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.merge(df_ta_clean,df_ts_clean, how='inner', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['matches'] = np.where(df_temp['created_at_x'] == df_temp['created_at_y'], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[df_temp['matches'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly proves that in both the tables timestamp are same. Hence we can delete created_at from tweet status dataste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean.drop(['created_at'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.Series(list(df_ta_clean.columns) + list(df_ts_clean.columns) + list(df_img_clean.columns))\n",
    "columns[columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisit Tidiness Issue#5: Rating distributed over two cloumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean['rating'] = (df_ta_clean['rating_numerator']/df_ta_clean['rating_denominator'])*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master = pd.merge(df_ta_clean,df_ts_clean, how='inner', on='tweet_id')\n",
    "df_archive_master = pd.merge(df_archive_master,df_img_clean, how='inner', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.to_csv('twitter_archive_master.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most preferred dog breed as pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['tweet_id'].count().nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least preferred dog breed as pet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['tweet_id'].count().nsmallest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most loved dog breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['favorite_count'].sum().nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not so loved dog breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['favorite_count'].sum().nsmallest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most re-tweeted dog breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['retweet_count'].sum().nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least re-tweeted dog breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['retweet_count'].sum().nsmallest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest rated Dog Breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.iloc[df_archive_master['rating'].nlargest().index]['first_pridicted_breed']\n",
    "df_archive_master.groupby(['first_pridicted_breed'])['rating'].mean().nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowest rated dog breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['rating'].mean().nsmallest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dog breed easily identifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['first_pridiction_confidence'].mean().nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dog breed difficult to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive_master.groupby(['first_pridicted_breed'])['first_pridiction_confidence'].mean().nsmallest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "There are many insights can be inferred based on the analysis done on cleaned and consolidated data. Many more can still be recovered by experienced data scientist by analysis. But from my little experince and the analysis done, here is what I can say\n",
    "1. Most loved(favourited)/ re-tweetd dog breed are the ones that are adopted most by people as pet.\n",
    "2. Highest rated dogs are not the most famous ones (favourited/re-tweeted).\n",
    "3. People tends to mark tweet as faovourite than re-tweeting them.\n",
    "4. It is highly likely that more the favourite count, higher the chanes of it being re-tweeted.\n",
    "5. There are dog breeds predicted with higher confidenece and some are having lower confidence level. This indicates that those which are easily identifiable has some distinct features. On the other hand some breed has very common features between them which probably lead to lower confidence. Here, I think it was a mistake to drop other p2 and p3 columns from prediction tabel. I assume the confidence are evenly distributed between 3 prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master.groupby(['first_pridicted_breed'])['tweet_id'].count().nlargest().to_frame()\n",
    "df.rename(columns = {'tweet_id': 'Tweet_Count'}, inplace = True)\n",
    "ax = df.plot.barh(title='Most preferred dog breed as pet')\n",
    "ax.set(xlabel='Tweet_count', ylabel='Breed')\n",
    "plt.savefig('most_preferred_dog_breed',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master.groupby(['first_pridicted_breed'])['tweet_id'].count().nsmallest().to_frame()\n",
    "df.rename(columns = {'tweet_id': 'Tweet_Count'}, inplace = True)\n",
    "ax = df.plot.barh(title='Least preferred dog breed as pet')\n",
    "ax.set(xlabel='Tweet_count', ylabel='Breed')\n",
    "plt.savefig('least_preferred_dog_breed',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master.groupby(['first_pridicted_breed'])['favorite_count'].sum().nlargest().to_frame()\n",
    "ax = df.plot.barh(title='Most favoured dog breed')\n",
    "ax.set(xlabel='favorite_count', ylabel='Breed')\n",
    "plt.savefig('most_favoured_dog_breed',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master.groupby(['first_pridicted_breed'])['favorite_count'].sum().nsmallest().to_frame()\n",
    "ax = df.plot.barh(title='Least favoured dog breed')\n",
    "ax.set(xlabel='favorite_count', ylabel='Breed')\n",
    "plt.savefig('least_favoured_dog_breed',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master.groupby(['first_pridicted_breed'])['retweet_count'].sum().nsmallest().to_frame()\n",
    "ax = df.plot.barh(title='Most re-tweeted dog breed')\n",
    "ax.set(xlabel='retweet_count', ylabel='Breed')\n",
    "plt.savefig('most_re-tweeted_dog_breed',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master.groupby(['first_pridicted_breed'])['retweet_count'].sum().nlargest().to_frame()\n",
    "ax = df.plot.barh(title='Most re-tweeted dog breed')\n",
    "ax.set(xlabel='retweet_count', ylabel='Breed')\n",
    "plt.savefig('least_re-tweeted_dog_breed',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_archive_master.groupby(['first_pridicted_breed'])['first_pridiction_confidence'].mean().nlargest()\n",
    "ax = df.plot.barh(title='Easily identifiable dog breed')\n",
    "ax.set(xlabel='Predicted Confidence', ylabel='Breed')\n",
    "plt.savefig('breed_easily_identifiable',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_archive_master.groupby(['first_pridicted_breed'])['first_pridiction_confidence'].mean().nsmallest()\n",
    "ax = df.plot.barh(title='Dog breed difficult to identofy')\n",
    "ax.set(xlabel='Predicted Confidence', ylabel='Breed')\n",
    "plt.savefig('breed_not_easily_identifiable',\n",
    "            bbox_inches =\"tight\",\n",
    "            pad_inches = 0.2,\n",
    "            transparent = True,\n",
    "            facecolor =\"g\",\n",
    "            edgecolor ='r',\n",
    "            orientation ='landscape')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between favourite, retweet, rating and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_archive_master[['favorite_count','retweet_count','rating','first_pridiction_confidence']]\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
